<!-- HEADER -->
<div id="header_wrap" class="outer">
<header class="inner">
<h1 id="project_title">
<span style="font-size:90% !important">New interfaces for teaching with NEST:</span>
</h1>
<h2 id="project_tagline">
Hands-on with the NEST Desktop GUI and NESTML code generation
</h2>
</header>
</div>
<!-- MAIN CONTENT -->
<div id="main_content_wrap" class="outer">
<section id="main_content" class="inner">
<link rel="stylesheet" type="text/css" media="screen" href="https://pages-themes.github.io/slate/assets/css/style.css?v=dd924ed8bde9d034c169c8f6d051bf93723eabbd">
<style>
/* class applies to select element itself, not a wrapper element */
.select-css {
    font-family: sans-serif;
    color: #444;
    line-height: 1.2;
    margin-bottom: .3em;
    padding: .6em 1.4em .5em .8em;
    max-width: 100%; /* useful when width is set to anything other than 100% */
    box-sizing: border-box;
    border: 1px solid #aaa;
    box-shadow: 0 1px 0 1px rgba(0,0,0,.04);
    border-radius: .5em;
    -moz-appearance: none;
    -webkit-appearance: none;
    appearance: none;
    background-color: #fff;
    /* note: bg image below uses 2 urls. The first is an svg data uri for the arrow icon, and the second is the gradient. 
        for the icon, if you want to change the color, be sure to use `%23` instead of `#`, since it's a url. You can also swap in a different svg icon or an external image reference
        
    */
    background-image: url('data:image/svg+xml;charset=US-ASCII,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%22292.4%22%20height%3D%22292.4%22%3E%3Cpath%20fill%3D%22%23007CB2%22%20d%3D%22M287%2069.4a17.6%2017.6%200%200%200-13-5.4H18.4c-5%200-9.3%201.8-12.9%205.4A17.6%2017.6%200%200%200%200%2082.2c0%205%201.8%209.3%205.4%2012.9l128%20127.9c3.6%203.6%207.8%205.4%2012.8%205.4s9.2-1.8%2012.8-5.4L287%2095c3.5-3.5%205.4-7.8%205.4-12.8%200-5-1.9-9.2-5.5-12.8z%22%2F%3E%3C%2Fsvg%3E'),
      linear-gradient(to bottom, #ffffff 0%,#e5e5e5 100%);
    background-repeat: no-repeat, repeat;
    /* arrow icon position (1em from the right, 50% vertical) , then gradient position*/
    background-position: right .7em top 50%, 0 0;
    /* icon size, then gradient */
    background-size: .65em auto, 100%;
}
/* Hide arrow icon in IE browsers */
.select-css::-ms-expand {
    display: none;
}
/* Hover style */
.select-css:hover {
    border-color: #888;
}
/* Focus style */
.select-css:focus {
    border-color: #aaa;
    /* It'd be nice to use -webkit-focus-ring-color here but it doesn't work on box-shadow */
    box-shadow: 0 0 1px 3px rgba(59, 153, 252, .7);
    box-shadow: 0 0 0 3px -moz-mac-focusring;
    color: #222; 
    outline: none;
}

/* Set options to normal weight */
.select-css option {
    font-weight:normal;
}

/* Support for rtl text, explicit support for Arabic and Hebrew */
*[dir="rtl"] .select-css, :root:lang(ar) .select-css, :root:lang(iw) .select-css {
    background-position: left .7em top 50%, 0 0;
    padding: .6em .8em .5em 1.4em;
}

/* Disabled styles */
.select-css:disabled, .select-css[aria-disabled=true] {
    color: graytext;
    background-image: url('data:image/svg+xml;charset=US-ASCII,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%22292.4%22%20height%3D%22292.4%22%3E%3Cpath%20fill%3D%22graytext%22%20d%3D%22M287%2069.4a17.6%2017.6%200%200%200-13-5.4H18.4c-5%200-9.3%201.8-12.9%205.4A17.6%2017.6%200%200%200%200%2082.2c0%205%201.8%209.3%205.4%2012.9l128%20127.9c3.6%203.6%207.8%205.4%2012.8%205.4s9.2-1.8%2012.8-5.4L287%2095c3.5-3.5%205.4-7.8%205.4-12.8%200-5-1.9-9.2-5.5-12.8z%22%2F%3E%3C%2Fsvg%3E'),
      linear-gradient(to bottom, #ffffff 0%,#e5e5e5 100%);
}

.select-css:disabled:hover, .select-css[aria-disabled=true] {
    border-color: #aaa;
}
</style>
<script src="moment.js"></script>
<script src="moment-timezone-with-data.js"></script>
<p style="margin-top: -1em; text-align: center; font-style: italic !important">
An online tutorial at the <a href="https://www.cnsorg.org/cns-2020">29th Annual Computational Neuroscience Meeting</a>, July 18th, 2020
</p>
<h2 id="description">Description</h2>
<p>NEST is established community software for the simulation of spiking neuronal network models capturing the full detail of biological network structures [1]. The simulator runs efficiently on a range of architectures from laptops to supercomputers [2]. Many peer-reviewed neuroscientific studies have used NEST as a simulation tool over the past 20 years. More recently, it has become a reference code for research on neuromorphic hardware systems [3].</p>
<p>This tutorial provides hands-on experience with recent improvements of NEST. In the past, starting out with NEST could be challenging for computational neuroscientists, as models and simulations had to be programmed using SLI, C++ or Python. NEST Desktop changes this: It is an entirely graphical approach to the construction and simulation of neuronal network models. It runs installation-free in the browser and has proven its value in several university courses. This opens the domain of NEST to the teaching of neuroscience for students with little programming experience.NESTML complements this new interface by enhancing the development process of neuron and synapse models. Advanced researchers often want to study specific features not provided by models already available in NEST. Instead of having to turn to C++, using NESTML they can write down differential equations and necessary state transitions in the mathematical notation they are used to. These descriptions are then automatically processed to generate machine-optimised code.</p>
<p>After a quick overview of the current status of NEST and upcoming new functionality, the tutorial works through a the construction of a balanced network to show how the combination of NEST Desktop and NESTML can be used in the modern workflow of a computational neuroscientist.</p>
<h3 id="citations">Citations</h3>
<p>[1] https://nest-simulator.readthedocs.io/</p>
<p>[2] Jordan J., Ippen T., Helias M., Kitayama I., Sato M., Igarashi J., Diesmann M., Kunkel S. (2018) Extremely Scalable Spiking Neuronal Network Simulation Code: From Laptops to Exascale Computers. Frontiers in Neuroinformatics 12: 2</p>
<p>[3] Gutzen R., von Papen, M., Trensch G., Quaglio P. Gr√ºn S., Denker M. (2018) Reproducible Neural Network Simulations: Statistical Methods for Model Validation on the Level of Network Activity Data. Frontiers in Neuroinformatics 12 (90)</p>
<h2 id="schedule">Schedule</h2>
<script>
var start_time = moment.tz("2020-07-18 12:00", "Europe/Berlin");

s = "<label for=\"tz-selector\">Timezone:&nbsp;</label>";
s += "<select class=\"select-css\" name=\"tz-selector\" id=\"tz-selector\" onChange=\"printTable(document.getElementById('schedule'), document.getElementById('tz-selector').value);\">";

moment.tz.names().forEach(function (item, index) {
    s += "<option value=\"" + item + "\"";
    if (item.localeCompare("Europe/Berlin") == 0) {
        s += " selected=\"selected\"";
    }
    s += ">" + item + "</option>";
});

s += "</select>";
document.write(s);

document.getElementById('tz-selector').value = "Europe/Berlin";

function printTable(el, in_tz) {
    //alert(in_tz);
    for (var i = 0; i < document.getElementsByClassName('timecell').length; ++i) {
        item = document.getElementsByClassName('timecell')[i];
        berlin_time = item.querySelector('noscript').innerHTML.replace(/^\s+|\s+$/g, '');
        //alert('old time: ' + berlin_time);
        //alert('attempted new time: ' + start_time.format("YYYY-MM-DD hh:mm:ss").slice(0, -8) + berlin_time + ":00");
        new_time = moment.tz(start_time.format("YYYY-MM-DD hh:mm:ss").slice(0, -8) + berlin_time + ":00", "Europe/Berlin").tz(in_tz);
        //alert('new time: ' + new_time.format());
        item.innerHTML = "<noscript>" + berlin_time + "</noscript>" + new_time.format('HH:mm');
    }
}
</script>
<div id="schedule" name="schedule">
<table>
<tr>
<th>
Time <noscript>(Berlin<br>timezone)</noscript>
</th>
<th>
Description
</th>
</tr>
<tr>
<td class="timecell">
<noscript>
16:00
</noscript>
16:00
</td>
<td>
Welcome and introduction to the NEST Initiative
</td>
</tr>
<tr>
<td class="timecell">
<noscript>
16:30
</noscript>
16:30
</td>
<td>
Hands-on with NEST Desktop
</td>
</tr>
<tr>
<td class="timecell">
<noscript>
17:30
</noscript>
17:30
</td>
<td>
Lunch break/social
</td>
</tr>
<tr>
<td class="timecell">
<noscript>
18:00
</noscript>
18:00
</td>
<td>
Hands-on running NEST from Jupyter Notebooks
</td>
</tr>
<tr>
<td class="timecell">
<noscript>
19:00
</noscript>
19:00
</td>
<td>
(break for CNS2020 keynote by Matt Botvinick)
</td>
</tr>
<tr>
<td class="timecell">
<noscript>
20:15
</noscript>
20:15
</td>
<td>
Introduction to NESTML
</td>
</tr>
<tr>
<td class="timecell">
<noscript>
20:45
</noscript>
20:45
</td>
<td>
Hands-on with NESTML and Jupyter Notebooks
</td>
</tr>
<tr>
<td class="timecell">
<noscript>
21:15
</noscript>
21:15
</td>
<td>
Hands-on with balanced network exercises
</td>
</tr>
<tr>
<td class="timecell">
<noscript>
21:45
</noscript>
21:45
</td>
<td>
Coffee break/social
</td>
</tr>
<tr>
<td class="timecell">
<noscript>
22:15
</noscript>
22:15
</td>
<td>
Hands-on with balanced network (continued)
</td>
</tr>
<tr>
<td class="timecell">
<noscript>
23:00
</noscript>
23:00
</td>
<td>
Closing
</td>
</tr>
</table>
</div>
<h2 id="links">Links</h2>
<div style="text-align:center">
<a href="https://nest-simulator.readthedocs.io/"><img src="https://nest-simulator.readthedocs.io/en/nest-2.20.1/_static/img/nest_logo.png" border="0"></a><br><a href="https://nest-simulator.readthedocs.io/"><span style="font-size:120%; font-weight: 120%">NEST Simulator</span></a>
</div>
<p>
NEST Simulator is a spiking neuron simulator which specialises in point neurons and neurons with few comparments. It can simulate synaptic plasticity, structural plasticity, gap junctions and countless other features on machines ranging from home PCs to high-performance computing systems.
</p>
<div style="text-align:center">
<a href="https://nest-desktop.readthedocs.io/"><img src="https://nest-desktop.readthedocs.io/en/latest/_images/nest-desktop-logo.png" border="0" width="240" height="222"></a><br><a href="https://nest-desktop.readthedocs.io/"><span style="font-size:120%; font-weight: 120%">NEST Desktop</span></a>
</div>
<p>
NEST Desktop is a web-based GUI application for NEST Simulator. It enables the rapid construction, parametrization, and instrumentation of neuronal network models.
</p>
<div style="text-align:center">
<a href="https://nestml.readthedocs.io/"><img src="https://nestml.readthedocs.io/en/latest/_static/nestml-logo.png" border="0" width="240" height="73"></a><br><a href="https://nestml.readthedocs.io/"><span style="font-size:120%; font-weight: 120%">NESTML</span></a>
</div>
<p>
NESTML is a domain-specific modeling language and code-generation toolchain. It supports the specification of neuron models in an intuitive and concise syntax. Optimised code generation for the target simulation platform couples a highly accessible language with good simulation performance.
</p>
<h2 id="registration">Registration</h2>
<p>Please don‚Äôt forget to register for the conference. Registration is free at <a href="https://www.cnsorg.org/cns-2020" class="uri">https://www.cnsorg.org/cns-2020</a>.</p>
<h2 id="connection-details">Connection details</h2>
<p>To allow for interactive sessions, tutorials will run as ‚Äúvirtual rooms‚Äù (i.e.¬†video calls) in CNS*2020. The platform is <a href="https://zoom.us/">Zoom</a>. It can run in your browser, and no account or installation is required. In some cases, installing the software on your local computer can improve the quality of the video and audio.</p>
<p>Tutorials are not recorded and are not livestreamed events on YouTube.</p>
<p><strong>The link for the tutorial video stream has been announced on the <a href="https://cns2020online.sched.com">Sched instance for CNS*2020</a></strong></p>
<h2 id="software-requirements">Software requirements</h2>
<p>We will provide login details for virtual machines on Human Brain Project (EBRAINS) infrastructure to registered participants. You will be able to access the required software directly from your browser, without requiring any installation. Access is provided to a NEST Desktop instance, as well as a <a href="https://jupyterhub.readthedocs.io/">JupyterHub</a> environment that includes NEST Simulator and NESTML.</p>
<p>You can also run the software on a local computer. We suggest using two Docker images that we provide:</p>
<ul>
<li><p><a href="https://github.com/clinssen/OCNS-2020-workshop/tree/master/docker_containers/nest-nestml-jupyterlab-ocns-tutorial">Jupyter Notebook server with NEST and NESTML support</a></p>
<p>Launches a Jupyter Notebook server on localhost at port 7003.</p>
<p>The image is available via DockerHub. To install:</p>
<pre><code>docker pull clifzju/nest-nestml-jupyterlab-ocns-tutorial</code></pre>
<p>Then run the image while forwarding the port:</p>
<pre><code>docker run -i -d -p 7003:7003 -t clifzju/nest-nestml-jupyterlab-ocns-tutorial</code></pre>
<p>You can then access the server in your browser by navigating to the URL <a href="http://localhost:7003" class="uri">http://localhost:7003</a>.</p></li>
<li><p><a href="https://github.com/clinssen/OCNS-2020-workshop/tree/master/docker_containers/nest-desktop-ocns-tutorial">NEST Desktop server</a></p>
<p>Slightly customised image based on the official <a href="https://nest-desktop.readthedocs.io/en/latest/deployer/deploy-docker.html">NEST Desktop docker image</a>.</p>
<p>The image is available via DockerHub. To install:</p>
<pre><code>docker pull clifzju/nest-desktop-ocns-tutorial</code></pre>
<p>Then run the image while forwarding the ports:</p>
<pre><code>docker run -i -d -p 7000:5000 -p 7001:8000 -t clifzju/nest-desktop-ocns-tutorial</code></pre>
<p>You can then access the server in your browser by navigating to the URL <a href="http://localhost:7001">http//localhost:7001</a>.</p></li>
</ul>
<p>You can run Docker containers interactively by omitting the <code>-d</code> parameter.</p>
<h2 id="organisation">Organisation</h2>
<p>This tutorial is organised by, alphabetically, <a href="https://www.fz-juelich.de/SharedDocs/Personen/IAS/JSC/EN/staff/linssen_c.html">Charl Linssen</a> (Forschungszentrum J√ºlich, Germany), <a href="https://www.fz-juelich.de/SharedDocs/Personen/INM/INM-6/EN/staff/Duarte_Renato.html?nn=1789538">Renato Duarte</a> (ibid.) and <a href="https://www.uni-trier.de/index.php?id=73522&amp;L=0">Sebastian Spreizer</a> (University of Trier, Germany). For general inquiries, please contact Charl at <a href="mailto:c.linssen@fz-juelich.de">c.linssen@fz-juelich.de</a>.</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>We acknowledge the use of <a href="https://fenix-ri.eu">Fenix Infrastructure</a> resources, which are partially funded from the European Union‚Äôs Horizon 2020 research and innovation programme through the ICEI project under the grant agreement No.¬†800858.</p>
</section>
</div>
<!-- FOOTER  -->
<div id="footer_wrap" class="outer">
<footer class="inner">
<p class="copyright" style="color: #cccccc">
Slate theme maintained by <a href="https://github.com/pages-themes">pages-themes</a> ‚Ä¢ Published with <a href="https://pages.github.com">GitHub Pages</a> ‚Ä¢ Timezone magic thanks to <a href="https://momentjs.com/">moment.js</a>
</p>
</footer>
</div>
